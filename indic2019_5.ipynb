{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indic2019 - 4",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatjain99/KairoGuard/blob/master/indic2019_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOHQBK7L2xGL",
        "colab_type": "code",
        "outputId": "0eb3496f-4c37-49b3-82cc-2482306878f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "import tensorboardcolab as tbc\n",
        "tbc = tbc.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://7909fcf6.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "looSmpWyzBB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = tbc.get_writer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnM84ryitc-r",
        "colab_type": "code",
        "outputId": "925f3a64-85f5-454b-d904-04793c38b3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 10\n",
        "nb_boxes=1\n",
        "grid_w=2\n",
        "grid_h=2\n",
        "cell_w=14\n",
        "cell_h=14\n",
        "img_w=28\n",
        "img_h=28\n",
        "img_channels = 1\n",
        "input_shape = (batch_size, img_w, img_h, img_channels)\n",
        "print(input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOSsq5V7RoiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_fn(data_record):\n",
        "    features = {\n",
        "      'image': tf.FixedLenFeature([], tf.string),\n",
        "      'label': tf.FixedLenFeature([5], tf.float32)\n",
        "    }\n",
        "    data = tf.parse_single_example(data_record, features)\n",
        "    \n",
        "    img1 = tf.decode_raw(data['image'], tf.float32)\n",
        "    img1 = tf.reshape(img1, (img_w, img_h, img_channels))\n",
        "    \n",
        "    \n",
        "    return img1, data['label']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HzVaO3XCJz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_pattern = '/gdrive/My Drive/indic2019/TFRecords/*.tfrecord'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyIJXPKB6r3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(files_pattern,  batch_size, mode=tf.estimator.ModeKeys.TRAIN):\n",
        "  files = tf.data.Dataset.list_files(files_pattern, shuffle=True)\n",
        "  dataset = files.apply(tf.contrib.data.parallel_interleave( lambda filename: tf.data.TFRecordDataset(filename), cycle_length=1))\n",
        "    \n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  if is_training:\n",
        "    buffer_size = batch_size * 2 + 1\n",
        "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
        "\n",
        "    # Transformation\n",
        "  dataset = dataset.map(extract_fn)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(2 * batch_size)\n",
        "\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "  features = {'images': image}\n",
        "  \n",
        "  \n",
        "  return features, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_0aCp8F0SJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def base_model(input,batch_size, input_shape):\n",
        "  \n",
        "  #print(input.shape)\n",
        "  #print(batch_size)\n",
        "  \n",
        "  \n",
        "  #Conv Layer - 1\n",
        "  x = tf.keras.layers.Conv2D(16,(5,5),activation='relu', input_shape = input_shape , name=\"Conv_1\",\n",
        "                             use_bias=True, kernel_initializer='glorot_uniform', \n",
        "                             bias_initializer='zeros')(input)\n",
        "  #x = tf.keras.layers.MaxPooling2D()(x)\n",
        "  print(x)\n",
        "  \n",
        "  #Flatten it out\n",
        "  x = tf.keras.layers.Flatten(name=\"Flatten_1\")(x)\n",
        "  print(\"After flatten\")\n",
        "  print(x)\n",
        "  \n",
        "  #Dense layer\n",
        "  x = tf.keras.layers.Dense(9216, activation=\"sigmoid\", name=\"Dense1\")(x)\n",
        "  #print(x)\n",
        "  x = tf.keras.layers.Dense(5, activation='sigmoid')(x)\n",
        "  print(x)\n",
        "  # x = tf.keras.layers.Reshape((2*2, (1*5)), name= 'model_final_reshape')(x)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxSTyMPbRWRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_columns():\n",
        "  feature_columns = {'images': tf.feature_column.numeric_column('images', (28,28))}\n",
        "  return feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcYye8xCKj00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_loss(labels,logits):\n",
        "  \n",
        "  print(logits)\n",
        "  \n",
        "  true_confidence = labels[:,0]\n",
        "  true_x=labels[:,1]\n",
        "  true_y=labels[:,2]\n",
        "  true_w=labels[:,3]\n",
        "  true_h=labels[:,4]\n",
        "\n",
        "  predict_confidence=logits[:,0]\n",
        "  predict_x=logits[:,1]\n",
        "  predict_y=logits[:,2]\n",
        "  predict_w=logits[:,3]\n",
        "  predict_h=logits[:,4]\t\n",
        "\n",
        "  xy_loss= K.square(true_x-predict_x) + K.square(true_y-predict_y)\n",
        "  wh_loss= K.square(K.sqrt(true_w)-K.sqrt(predict_w))+ K.square(K.sqrt(true_h)-K.sqrt(predict_h))\n",
        "\n",
        "  con_loss=K.square(true_confidence-predict_confidence)\n",
        "\n",
        "  loss= xy_loss + wh_loss + con_loss\n",
        "  return tf.math.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZUvo0Wupr49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "  \n",
        "  print(mode)\n",
        "  # Create the input layers from the features                                                                                               \n",
        "  feature_columns = list(get_feature_columns().values())\n",
        "  images = tf.feature_column.input_layer(features=features, feature_columns=feature_columns)\n",
        "  print('pre',images.shape)\n",
        "  images = tf.reshape(images, shape=(-1, 28, 28, 1),name='my_reshape')\n",
        "  print('post',images.shape)\n",
        "  print(images)\n",
        "\n",
        "  # batch_size = 300\n",
        "  # Calculate logits through CNN                                                                                                            \n",
        "  logits = base_model(images,batch_size, input_shape)\n",
        "  \n",
        "  print('Printing Logits')\n",
        "  print(logits)\n",
        "  print(\"Printing labels\")\n",
        "  print(labels)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "  #if mode in (tf.estimator.ModeKeys.PREDICT, tf.estimator.ModeKeys.EVAL):#To Do\n",
        "\n",
        "  if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    loss = loss=custom_loss(labels,logits)\n",
        "    #loss = tf.keras.losses.mean_squared_error(labels,logits)\n",
        "    tf.summary.scalar('Loss', loss)\n",
        "    #oss = custom_loss(labels,logits)\n",
        "    # tf.summary.scalar('Loss function', loss)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {'coordinates': logits}\n",
        "    export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
        "    return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
        "  #return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False,name='Adam')\n",
        "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  '''if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    eval_metric_ops = {\n",
        "        'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\n",
        "    }\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode, loss=loss, eval_metric_ops=eval_metric_ops)'''\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odFo6ksy6Tep",
        "colab_type": "code",
        "outputId": "6b56c595-4c21-465c-e34b-66bea0f64642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "run_config = tf.estimator.RunConfig(save_checkpoints_steps=10, model_dir='./Graph',save_summary_steps=10)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
        "\n",
        "# There is another Exporter named FinalExporter\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(input_fn= lambda:input_fn(files_pattern=input_pattern, batch_size = batch_size, mode=tf.estimator.ModeKeys.TRAIN))\n",
        "\n",
        "\n",
        "# eval_spec = tf.estimator.EvalSpec(\n",
        "#   input_fn=generate_input_fn(file_names=valid_data_files,\n",
        "#                              mode=tf.estimator.ModeKeys.EVAL,\n",
        "#                              batch_size=10)'\n",
        "#   steps=FLAGS.eval_steps, exporters=exporter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './Graph', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd55b96ab38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7fd55d7a9598>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE5EOPyAzMuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer.add_graph(tf.get_default_graph())\n",
        "writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MIqDV8qFbyy",
        "colab_type": "code",
        "outputId": "a09b9219-8045-47d7-8b02-084838c636a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "estimator.train(lambda: input_fn(files_pattern=input_pattern,  batch_size= batch_size, mode=tf.estimator.ModeKeys.TRAIN), steps=100000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "train\n",
            "pre (?, 784)\n",
            "post (?, 28, 28, 1)\n",
            "Tensor(\"my_reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
            "Tensor(\"Conv_1/Relu:0\", shape=(?, 24, 24, 16), dtype=float32)\n",
            "After flatten\n",
            "Tensor(\"Flatten_1/Reshape:0\", shape=(?, 9216), dtype=float32)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
            "Printing Logits\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
            "Printing labels\n",
            "Tensor(\"IteratorGetNext:1\", shape=(?, 5), dtype=float32, device=/device:CPU:0)\n",
            "Tensor(\"dense/Sigmoid:0\", shape=(?, 5), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.52047306, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 10 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 20 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 30 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 40 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 45 into ./Graph/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.2829814.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fd55c3868d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKt0rwpwSDZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn_predict():\n",
        " \n",
        "  dataset = tf.data.TFRecordDataset(['/gdrive/My Drive/indic2019/TFRecords/10_13.tfrecord'])\n",
        "    # Transformation\n",
        "  dataset = dataset.map(extract_fn)\n",
        "\n",
        "  image, label = dataset.make_one_shot_iterator().get_next()\n",
        "  features = {'images': image}\n",
        "  \n",
        "  \n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEo88MtBx97c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}